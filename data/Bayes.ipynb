{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pyro\n",
    "from math import pi\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from pyro.optim import Adam\n",
    "import pyro.distributions as dist\n",
    "from torch.distributions import constraints\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from matplotlib import animation, rc\n",
    "from IPython.display import HTML\n",
    "import torch.nn as nn\n",
    "from functools import partial\n",
    "import pandas as pd\n",
    "from pyro.contrib.autoguide import AutoDiagonalNormal\n",
    "from pyro.infer import EmpiricalMarginal, SVI, Trace_ELBO, TracePredictive\n",
    "import scipy.stats\n",
    "\n",
    "pyro.set_rng_seed(1)\n",
    "pyro.enable_validation(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_class(data_y):\n",
    "    classes = list(unique_classes)\n",
    "    print(classes)\n",
    "    for i in range(len(data_y)):\n",
    "        data_y[i] = int(classes.index(data_y[i]))\n",
    "    return data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setosa', 'versicolor', 'virginica']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "        2, 2, 2, 2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('iris.csv', sep=',', header=[0])\n",
    "data_x = torch.tensor(dataset.iloc[:,0:-1].values)\n",
    "data_y = dataset.iloc[:,-1]\n",
    "class_prob = data_y.value_counts(normalize = True)\n",
    "unique_classes = np.unique(data_y)\n",
    "class_amount = len(unique_classes)\n",
    "atr_amount = data_x.shape[1]\n",
    "data_y = torch.tensor(normalize_class(data_y)) #.unsqueeze(-1)\n",
    "print(data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6614]])\n",
      "tensor([[0.2669]])\n",
      "tensor([[0.0617]])\n",
      "tensor([[0.6213]])\n",
      "tensor([[-0.4519]])\n",
      "tensor([[-0.1661]])\n",
      "tensor([[-1.5228]])\n",
      "tensor([[0.3817]])\n",
      "tensor([[-1.0276]])\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 10):\n",
    "    print(pyro.sample('test', dist.Normal(torch.zeros(1, 1), 1.).independent(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The parameter concentration has invalid values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-6f010d5cceb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBeta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/distributions/beta.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, concentration1, concentration0, validate_args)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mconcentration1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcentration0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbroadcast_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcentration1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcentration0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mconcentration1_concentration0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mconcentration1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcentration0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dirichlet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDirichlet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconcentration1_concentration0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dirichlet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/distributions/dirichlet.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, concentration, validate_args)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcentration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcentration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mbatch_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcentration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcentration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDirichlet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_instance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/distributions/distribution.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch_shape, event_shape, validate_args)\u001b[0m\n\u001b[1;32m     34\u001b[0m                     \u001b[0;32mcontinue\u001b[0m  \u001b[0;31m# skip checking lazily-constructed args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mconstraint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The parameter {} has invalid values\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_instance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The parameter concentration has invalid values"
     ]
    }
   ],
   "source": [
    "dist.Beta(torch.zeros(1, 1), torch.tensor(1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "def model(atr, claz):\n",
    "    #print(claz)\n",
    "    class_prob = pyro.sample('class_prob', dist.Beta(torch.tensor(1.0), torch.tensor(1.0)).expand([class_amount]).independent(1))\n",
    "    #print(class_prob)\n",
    "    norm_class_prob = class_prob/torch.sum(class_prob)\n",
    "    print('norm',norm_class_prob)\n",
    "    #print(norm_class_prob)\n",
    "    with pyro.plate('class_prob_loop', len(claz)):\n",
    "        pyro.sample('obs', dist.Categorical(probs=norm_class_prob), obs=claz)\n",
    "    \n",
    "\n",
    "def guide(atr, claz):\n",
    "    class_prob = pyro.param('class', torch.rand(1, class_amount)/class_amount)\n",
    "    norm_class_prob = class_prob/torch.sum(class_prob)\n",
    "    print(norm_class_prob)\n",
    "    \n",
    "    pyro.sample('class_prob', dist.Categorical(probs=norm_class_prob))\n",
    "    \n",
    "    #means = pyro.param('mean', pyro.distributions.Normal(torch.zeros(class_amount, atr_amount), 1.0))\n",
    "    #stds = pyro.param('std', pyro.distributions.LogNormal(torch.zeros(class_amount, atr_amount), 0.1), constraint=constraints.positive)\n",
    "    \n",
    "    \n",
    "guide(data_x, data_y)\n",
    "    \n",
    "\n",
    "\n",
    "pyro.clear_param_store()\n",
    "\n",
    "def train(X, Y):\n",
    "    pyro.clear_param_store()\n",
    "    num_iterations=1000\n",
    "    optim = pyro.optim.Adam({\"lr\": 0.05})\n",
    "    svi = pyro.infer.SVI(model, guide, optim, loss=pyro.infer.Trace_ELBO(), num_samples=len(X))\n",
    "    losses = list()\n",
    "    t=tqdm(range(num_iterations))\n",
    "    for j in t:\n",
    "        loss = svi.step(X, Y)\n",
    "        losses.append(loss)\n",
    "        t.set_postfix(loss=loss)\n",
    "    return (svi, losses)\n",
    "\n",
    "train(data_x, data_y)\n",
    "\n",
    "#pyro.params\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, value in pyro.get_param_store().items():\n",
    "    print(name, pyro.param(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.cat((torch.zeros(2691), torch.ones(7423 - 2691)))\n",
    "\n",
    "def model(data):\n",
    "    alpha = torch.tensor(6.0)\n",
    "    beta = torch.tensor(10.0)\n",
    "    wroc_probs = pyro.sample('wroc_probs', dist.Beta(alpha, beta).expand([2]).independent(1))\n",
    "    norm_wroc_probs = wroc_probs/torch.sum(wroc_probs)\n",
    "    with pyro.iarange('data_loop', len(data)):\n",
    "        pyro.sample('obs', dist.Categorical(probs=norm_wroc_probs), obs=data)\n",
    "        \n",
    "def guide(data):\n",
    "    alphas = pyro.param('alphas', torch.tensor(15.).expand(2), constraint=constraints.positive)\n",
    "    betas = pyro.param('betas', torch.tensor(26.).expand(2), constraint=constraints.positive) \n",
    "\n",
    "    pyro.sample('wroc_probs', dist.Beta(alphas, betas).independent(1))\n",
    "    \n",
    "    \n",
    "def train(data):\n",
    "    pyro.clear_param_store()\n",
    "    num_iterations=1000\n",
    "    optim = pyro.optim.Adam({\"lr\": 0.05})\n",
    "    svi = pyro.infer.SVI(model, guide, optim, loss=pyro.infer.Trace_ELBO(), num_samples=len(data))\n",
    "    losses = list()\n",
    "    t=tqdm(range(num_iterations))\n",
    "    for j in t:\n",
    "        loss = svi.step(data)\n",
    "        losses.append(loss)\n",
    "        t.set_postfix(loss=loss)\n",
    "    return (svi, losses)\n",
    "\n",
    "#train(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [02:21<00:00, 70.67it/s, loss=77.9]\n"
     ]
    }
   ],
   "source": [
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "class NaiveBayes(nn.Module):\n",
    "    def __init__(self, data_x, data_y):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.data_x = data_x\n",
    "        self.data_y = data_y\n",
    "        \n",
    "        #print(data_y)\n",
    "        self.unique_classes = np.unique(data_y)\n",
    "        self.class_amount = len(np.unique(data_y))\n",
    "        self.atr_amount = data_x.shape[1]\n",
    "        self.shape = (self.class_amount, self.atr_amount)\n",
    "        \n",
    "        #self.class_prob = self.data_y.value_counts(normalize = True)\n",
    "        self.register_parameter(\"classes\", nn.Parameter(torch.ones(self.class_amount)/self.class_amount))\n",
    "        self.register_parameter(\"locs\", nn.Parameter(torch.zeros(self.shape)))\n",
    "        self.register_parameter(\"scales\", nn.Parameter(torch.ones(self.shape)))\n",
    "        \n",
    "    def predict(self, x):\n",
    "        item_prob = []\n",
    "        for claz_i in range(self.class_amount):\n",
    "            claz_prob = self.classes[claz_i]\n",
    "            #print('1', claz_prob)\n",
    "            for atr_i in range(self.atr_amount):\n",
    "                    #print(claz_prob)\n",
    "                mean = self.locs[claz_i][atr_i].detach().numpy()\n",
    "                std = self.scales[claz_i][atr_i].detach().numpy()\n",
    "                print(mean, std)\n",
    "                claz_prob *= (1/(np.sqrt(2*np.pi*(std ** 2)))) * (np.e ** (-((x[atr_i]-torch.tensor(mean)) ** 2)/(2*std ** 2)))\n",
    "            #print('2', claz_prob)\n",
    "            item_prob.append(claz_prob.item())\n",
    "            print('3', item_prob)\n",
    "        return torch.tensor(item_prob)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x[:,np.newaxis,:] #.double()\n",
    "\n",
    "        v = (torch.sum(- 0.5 * torch.log(1/(2. * pi * self.scales))\n",
    "                - (x - self.locs.double())**2 / torch.abs(self.scales) / 2, dim=-1)\n",
    "                     ) #+ torch.log(self.classes))\n",
    "        #print (\"org \", v, \"\\n\\n\\n\")\n",
    "        \n",
    "        #print(\"ret \", ret, '\\n\\n')\n",
    "        #print(torch.tensor(ret))\n",
    "        #print(v, v.shape)\n",
    "        \n",
    "        return v\n",
    "    \n",
    "        ret = []\n",
    "        for item in x:\n",
    "            #print(item)\n",
    "            item_prob = []\n",
    "            for claz_i in range(self.class_amount):\n",
    "                claz_prob = self.classes[claz_i]\n",
    "                for atr_i in range(self.atr_amount):\n",
    "                    #print(claz_prob)\n",
    "                    mean = self.locs[claz_i][atr_i].item()\n",
    "                    std = self.scales[claz_i][atr_i].item()\n",
    "                    print(mean, std)\n",
    "                    claz_prob *= (1/(np.sqrt(2*np.pi*(std ** 2)))) * (np.e ** (-((item[atr_i]-mean) ** 2)/(2*std ** 2)))\n",
    "                    \n",
    "                    #p *= (1/(np.sqrt(2*np.pi*(std ** 2)))) * (np.e ** (-((element-mean) ** 2)/(2*std ** 2)))\n",
    "                \n",
    "                item_prob.append(claz_prob.item())\n",
    "                print('item', item_prob)\n",
    "            #print(ret)\n",
    "            ret.append(item_prob)\n",
    "            #print('aff',ret)\n",
    "        \n",
    "        print(ret)\n",
    "        ret = torch.tensor(ret)\n",
    "        return v\n",
    "        #print(x)\n",
    "        #print(self.scales)\n",
    "        #print(self.locs)\n",
    "        #print(self.classes)\n",
    "        \n",
    "    \n",
    "    def model(self, data_x, data_y):\n",
    "        #print(data_y)\n",
    "        #data_y = data_y.unsqueeze(-1)\n",
    "        #print(data_y)\n",
    "        means = pyro.distributions.Normal(loc=torch.zeros_like(self.locs), scale=torch.ones_like(self.scales)).to_event(2)\n",
    "        variances = pyro.distributions.LogNormal(loc=torch.ones_like(self.scales), scale=torch.ones_like(self.scales)).to_event(2)\n",
    "        classes_priors = pyro.distributions.Dirichlet(concentration=torch.ones(self.class_amount))\n",
    "        #classes_priors = classes_priors/torch.sum(classes_priors)\n",
    "        \n",
    "        priors = {'locs': means, 'scales': variances, \"classes\": classes_priors}\n",
    "        lifted_module = pyro.random_module(\"module\", self, priors)\n",
    "        lifted_model = lifted_module()\n",
    "        \n",
    "        with pyro.plate(\"map\", len(data_x)):\n",
    "            class_prob = lifted_model(data_x)\n",
    "            #pyro.sample(\"obs_cl\",pyro.distributions.Categorical(probs=lifted_model.classes),obs=data_y)\n",
    "            pyro.sample(\"obs\",pyro.distributions.Categorical(logits=class_prob),obs=data_y)\n",
    "            return class_prob\n",
    "        \n",
    "        \"\"\"\n",
    "        with pyro.plate('classes', self.class_amount):\n",
    "            classes = pyro.sample(\"class\", pyro.distributions.Categorical(lifted_model.classes), obs=data_y)\n",
    "            with pyro.plate(\"map\", len(data_x)):\n",
    "                class_prob = lifted_model(data_x)\n",
    "                print('class prob' , class_prob)\n",
    "            #    pyro.sample(\"obs\",pyro.distributions.Categorical(probs=lifted_model.classes),obs=data_y)\n",
    "                pyro.sample(\"obs\",pyro.distributions.Categorical(logits=class_prob),obs=data_y)\n",
    "                return class_prob\"\"\"\n",
    "        \n",
    "    def guide(self, data_x, data_y):\n",
    "        means_m = pyro.param(\"means_m\",torch.ones_like(self.locs))\n",
    "        means_s = pyro.param(\"means_s\",torch.ones_like(self.locs), constraint=constraints.positive)\n",
    "        variances_c = pyro.param(\"variances_a\", torch.ones_like(self.scales), constraint=constraints.positive)\n",
    "        variances_r = pyro.param(\"variances_b\", torch.ones_like(self.scales), constraint=constraints.positive)\n",
    "        classes_priors_c = pyro.param(\"classes_priors_c\", torch.ones(self.class_amount)/self.class_amount, constraint=constraints.positive)\n",
    "        classes_priors_c = classes_priors_c/torch.sum(classes_priors_c)\n",
    "        \n",
    "        locs = pyro.distributions.Normal(loc=means_m, scale=means_s).independent(2)\n",
    "        scales = pyro.distributions.LogNormal(loc=variances_c,scale=variances_r).independent(2)\n",
    "        classes = pyro.distributions.Dirichlet(concentration=classes_priors_c)\n",
    "        \n",
    "        \n",
    "        \n",
    "        priors = {'locs': locs, 'scales': scales, \"classes\": classes}\n",
    "        lifted_module = pyro.random_module(\"module\", self, priors)\n",
    "        return lifted_module()\n",
    "    \n",
    "    def train(self, data_x, data_y):\n",
    "        pyro.clear_param_store()\n",
    "        num_iterations=10000\n",
    "        optim = pyro.optim.Adam({\"lr\": 0.05})\n",
    "        svi = pyro.infer.SVI(self.model, self.guide, optim, loss=pyro.infer.Trace_ELBO(), num_samples=len(data_x))\n",
    "        losses = list()\n",
    "        t=tqdm(range(num_iterations))\n",
    "        for j in t:\n",
    "            loss = svi.step(data_x, data_y)\n",
    "            losses.append(loss)\n",
    "            t.set_postfix(loss=loss)\n",
    "        return (svi, losses)\n",
    "    \n",
    "naive_bayes = NaiveBayes(data_x, data_y)\n",
    "svi, losses = naive_bayes.train(data_x, data_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([150, 4])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "(- 0.5 * torch.log(1/(2. * pi * data_x)) + data_x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "means_m tensor([[ 0.5949,  0.6524, -1.0814, -0.1030],\n",
      "        [ 0.6893, -0.2362,  1.6876,  0.1955],\n",
      "        [ 0.4144, -1.4858,  0.6019,  2.8829]], requires_grad=True)\n",
      "means_s tensor([[0.6529, 1.0211, 0.1759, 0.7522],\n",
      "        [0.6437, 0.0811, 0.1085, 0.2129],\n",
      "        [0.6312, 0.0780, 0.7963, 0.2242]], grad_fn=<AddBackward0>)\n",
      "variances_a tensor([[2.3681e+00, 2.1530e+00, 2.3160e-04, 1.1421e+00],\n",
      "        [2.8310e+00, 2.1186e-02, 6.6174e-04, 1.1269e-03],\n",
      "        [1.9714e+00, 8.8332e-03, 2.6977e+00, 3.9348e-04]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "variances_b tensor([[0.2943, 0.4714, 0.0889, 0.6801],\n",
      "        [0.1282, 0.0572, 0.0798, 0.3421],\n",
      "        [0.1442, 0.0395, 0.2421, 0.3204]], grad_fn=<AddBackward0>)\n",
      "classes_priors_c tensor([0.2319, 0.3249, 0.4041], grad_fn=<AddBackward0>)\n",
      "tensor([[6.5000, 3.0000, 5.2000, 2.0000],\n",
      "        [6.2000, 3.4000, 5.4000, 2.3000],\n",
      "        [5.9000, 3.0000, 5.1000, 1.8000]])\n"
     ]
    }
   ],
   "source": [
    "for name, value in pyro.get_param_store().items():\n",
    "    print(name, pyro.param(name))\n",
    "    \n",
    "print(data_x[-3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "0 0\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "2 1\n",
      "1 1\n",
      "2 1\n",
      "1 1\n",
      "2 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "2 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "2 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "1 1\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n",
      "2 2\n"
     ]
    }
   ],
   "source": [
    "model = naive_bayes.guide(None, None)\n",
    "res = model(data_x)\n",
    "for i in range(150):\n",
    "    values, indices = res[i].max(0)\n",
    "    if(indices.item()==)\n",
    "    print(, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrapped_model(data_x, data_y):\n",
    "    model_result=probabilistic_model(data_x, data_y)\n",
    "    pyro.sample(\"prediction\", pyro.distributions.Delta(model_result))\n",
    "    \n",
    "posterior = svi.run(data_x, data_y)\n",
    "\n",
    "trace_pred = TracePredictive(wrapped_model,\n",
    "                             posterior,\n",
    "                             num_samples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3.2065e-17, 4.6777e-18, 2.2602e-05],\n",
      "        [3.4421e-15, 2.8109e-17, 3.2038e-05],\n",
      "        [1.2497e-13, 1.9683e-16, 3.6581e-05],\n",
      "        [8.0041e-13, 2.3486e-16, 3.2419e-05],\n",
      "        [2.2633e-16, 1.0916e-17, 2.2846e-05],\n",
      "        [2.1371e-20, 1.8381e-19, 1.0562e-05],\n",
      "        [5.7566e-13, 4.1603e-16, 3.1928e-05],\n",
      "        [2.8567e-16, 8.0975e-18, 2.2447e-05],\n",
      "        [2.8730e-11, 1.6324e-15, 4.4164e-05],\n",
      "        [3.0177e-15, 1.4728e-17, 2.7078e-05],\n",
      "        [2.9782e-20, 2.2300e-19, 1.5086e-05],\n",
      "        [1.4391e-14, 3.0880e-17, 2.2258e-05],\n",
      "        [2.3774e-14, 4.8123e-17, 3.3642e-05],\n",
      "        [1.2961e-10, 6.3027e-15, 5.8852e-05],\n",
      "        [9.6089e-25, 1.2642e-20, 1.3506e-05],\n",
      "        [6.5534e-24, 2.0657e-20, 8.4525e-06],\n",
      "        [2.3378e-20, 7.1859e-19, 1.7117e-05],\n",
      "        [3.2043e-17, 6.2273e-18, 2.2753e-05],\n",
      "        [1.5570e-23, 8.6697e-21, 9.0989e-06],\n",
      "        [2.1026e-17, 4.2355e-18, 1.7398e-05],\n",
      "        [4.1775e-20, 1.1480e-19, 1.3477e-05],\n",
      "        [2.4051e-17, 5.6668e-18, 1.8404e-05],\n",
      "        [4.7639e-13, 9.6473e-16, 4.1264e-05],\n",
      "        [3.7866e-17, 3.8438e-18, 1.7261e-05],\n",
      "        [1.3242e-14, 9.7876e-18, 1.4361e-05],\n",
      "        [4.4149e-16, 6.0715e-18, 2.3719e-05],\n",
      "        [2.7800e-16, 9.9876e-18, 2.0008e-05],\n",
      "        [3.6269e-18, 1.3939e-18, 1.8932e-05],\n",
      "        [4.1988e-18, 1.9761e-18, 2.2306e-05],\n",
      "        [1.1721e-13, 7.2610e-17, 2.5858e-05],\n",
      "        [2.0429e-14, 3.2359e-17, 2.5540e-05],\n",
      "        [4.3716e-20, 4.1063e-19, 1.7698e-05],\n",
      "        [1.5677e-18, 9.2497e-19, 1.3665e-05],\n",
      "        [1.3566e-21, 1.1260e-19, 1.2073e-05],\n",
      "        [3.0177e-15, 1.4728e-17, 2.7078e-05],\n",
      "        [3.8386e-16, 2.1540e-17, 3.3806e-05],\n",
      "        [3.7257e-21, 1.7599e-19, 1.9501e-05],\n",
      "        [3.0177e-15, 1.4728e-17, 2.7078e-05],\n",
      "        [2.6386e-11, 2.2068e-15, 4.7056e-05],\n",
      "        [3.5567e-17, 3.4110e-18, 2.1132e-05],\n",
      "        [2.6237e-16, 2.0268e-17, 2.6858e-05],\n",
      "        [9.7777e-12, 1.4665e-15, 5.8704e-05],\n",
      "        [2.1151e-11, 2.1424e-15, 4.3095e-05],\n",
      "        [2.4210e-16, 1.6295e-17, 1.9071e-05],\n",
      "        [1.8840e-17, 1.2438e-18, 9.9393e-06],\n",
      "        [2.3799e-14, 8.6423e-17, 3.4181e-05],\n",
      "        [2.0552e-17, 2.2436e-18, 1.5240e-05],\n",
      "        [7.3060e-13, 3.2257e-16, 3.4806e-05],\n",
      "        [2.9919e-19, 5.5169e-19, 1.6081e-05],\n",
      "        [3.2935e-16, 1.1474e-17, 2.6414e-05],\n",
      "        [2.8330e-41, 8.0124e-34, 6.3289e-10],\n",
      "        [1.4194e-32, 3.5751e-30, 2.3738e-09],\n",
      "        [8.4799e-40, 4.7335e-34, 2.8216e-10],\n",
      "        [3.1249e-21, 1.2521e-24, 4.9425e-08],\n",
      "        [8.7255e-34, 5.5927e-31, 1.6971e-09],\n",
      "        [9.1740e-24, 3.2205e-27, 4.8770e-09],\n",
      "        [2.1722e-31, 1.9912e-30, 9.9728e-10],\n",
      "        [2.6091e-15, 2.0897e-20, 7.7958e-07],\n",
      "        [3.3952e-35, 1.4462e-31, 1.5783e-09],\n",
      "        [2.3578e-18, 4.4265e-23, 7.3243e-08],\n",
      "        [4.1398e-16, 2.4763e-21, 4.4735e-07],\n",
      "        [4.5915e-26, 6.9535e-27, 1.2762e-08],\n",
      "        [7.9159e-27, 6.2807e-27, 3.8131e-08],\n",
      "        [1.2884e-28, 1.2827e-29, 1.4498e-09],\n",
      "        [2.0779e-22, 8.4413e-24, 1.5199e-07],\n",
      "        [1.1981e-36, 2.9744e-31, 3.0652e-09],\n",
      "        [8.8827e-23, 1.0562e-26, 4.5861e-09],\n",
      "        [1.1061e-24, 1.9538e-26, 2.5113e-08],\n",
      "        [1.5134e-29, 3.2268e-29, 4.0683e-09],\n",
      "        [2.5685e-22, 7.4238e-25, 6.4633e-08],\n",
      "        [1.9822e-26, 5.6826e-29, 8.3653e-10],\n",
      "        [2.6152e-28, 3.5495e-27, 2.7145e-08],\n",
      "        [4.2236e-31, 3.2952e-31, 5.7417e-10],\n",
      "        [1.4992e-28, 9.6834e-30, 1.5731e-09],\n",
      "        [2.4592e-32, 1.5017e-29, 6.4868e-09],\n",
      "        [3.5378e-35, 8.9276e-31, 3.4634e-09],\n",
      "        [4.0328e-38, 3.2691e-33, 5.6359e-10],\n",
      "        [7.0614e-37, 2.1591e-33, 2.0443e-10],\n",
      "        [2.5282e-27, 2.2326e-28, 3.6292e-09],\n",
      "        [2.5181e-23, 4.0965e-24, 2.3351e-07],\n",
      "        [3.5014e-21, 3.9907e-24, 1.0247e-07],\n",
      "        [3.8308e-21, 6.8474e-24, 1.4727e-07],\n",
      "        [1.2339e-24, 1.2707e-25, 5.1478e-08],\n",
      "        [1.7110e-27, 1.1794e-30, 2.4937e-10],\n",
      "        [1.1213e-20, 6.7363e-26, 5.2287e-09],\n",
      "        [1.3948e-27, 2.3212e-28, 2.8270e-09],\n",
      "        [8.9572e-37, 2.5975e-32, 8.2384e-10],\n",
      "        [8.2215e-31, 2.0171e-29, 5.8209e-09],\n",
      "        [1.3037e-22, 2.0876e-25, 2.4218e-08],\n",
      "        [2.6541e-21, 1.2244e-24, 4.6071e-08],\n",
      "        [1.8104e-21, 4.2936e-26, 9.3432e-09],\n",
      "        [1.2692e-28, 3.0253e-29, 2.1585e-09],\n",
      "        [1.2556e-24, 6.0535e-26, 3.6980e-08],\n",
      "        [3.7899e-16, 9.0223e-21, 7.6053e-07],\n",
      "        [1.6277e-22, 9.8884e-26, 1.8545e-08],\n",
      "        [9.8271e-24, 3.1578e-26, 1.5636e-08],\n",
      "        [1.0645e-23, 3.7353e-26, 1.5999e-08],\n",
      "        [1.0239e-29, 1.1935e-28, 7.5333e-09],\n",
      "        [4.6694e-17, 2.8517e-20, 1.5614e-06],\n",
      "        [1.2731e-23, 8.3233e-26, 2.4599e-08],\n",
      "        [3.7898e-32, 7.8971e-36, 9.0939e-13],\n",
      "        [3.5174e-25, 1.0928e-29, 2.6070e-10],\n",
      "        [2.2261e-43, 3.7389e-39, 1.1736e-12],\n",
      "        [1.2815e-31, 4.6639e-34, 1.3507e-11],\n",
      "        [1.6133e-34, 8.5978e-36, 3.1985e-12],\n",
      "        [5.2874e-52, 3.4456e-45, 1.1224e-14],\n",
      "        [8.2409e-16, 7.1997e-24, 8.1936e-09],\n",
      "        [1.0842e-46, 3.5598e-42, 1.1028e-13],\n",
      "        [4.7425e-37, 8.5379e-37, 3.8869e-12],\n",
      "        [1.8384e-45, 1.2637e-40, 2.1402e-13],\n",
      "        [2.9768e-34, 8.8441e-33, 1.2206e-10],\n",
      "        [9.7454e-33, 3.7283e-33, 6.2613e-11],\n",
      "        [1.2658e-38, 7.2787e-36, 1.3366e-11],\n",
      "        [6.0331e-24, 7.9635e-29, 4.6898e-10],\n",
      "        [2.5407e-25, 1.2847e-29, 2.0284e-10],\n",
      "        [4.8372e-33, 4.1044e-33, 4.3063e-11],\n",
      "        [2.6621e-34, 1.5672e-34, 1.8925e-11],\n",
      "        [2.9633e-54, 2.7519e-46, 3.5279e-15],\n",
      "        [8.5381e-54, 2.8613e-47, 1.5568e-15],\n",
      "        [2.9594e-27, 2.8501e-30, 4.9530e-10],\n",
      "        [2.4124e-40, 3.1206e-37, 3.5391e-12],\n",
      "        [6.3308e-23, 4.9758e-28, 7.1582e-10],\n",
      "        [1.0633e-53, 2.9673e-46, 6.0955e-15],\n",
      "        [3.1869e-31, 4.3545e-31, 4.8756e-10],\n",
      "        [2.0701e-37, 2.6473e-36, 4.3329e-12],\n",
      "        [4.6681e-45, 3.1995e-40, 6.2324e-13],\n",
      "        [6.2490e-30, 2.9772e-30, 7.9980e-10],\n",
      "        [8.4614e-29, 3.2332e-30, 4.9982e-10],\n",
      "        [5.9127e-33, 2.0021e-34, 1.1673e-11],\n",
      "        [7.8773e-45, 2.3794e-39, 2.2478e-12],\n",
      "        [3.2975e-48, 1.1518e-41, 3.3585e-13],\n",
      "        [1.2254e-57, 7.5471e-46, 2.1252e-14],\n",
      "        [5.6478e-33, 2.0733e-34, 1.1189e-11],\n",
      "        [2.6411e-31, 4.9309e-32, 1.9776e-10],\n",
      "        [6.9905e-29, 2.4374e-33, 1.9718e-11],\n",
      "        [1.6136e-53, 3.5262e-43, 2.0080e-13],\n",
      "        [5.5818e-32, 5.5504e-34, 8.4509e-12],\n",
      "        [5.4504e-33, 4.4451e-34, 1.9564e-11],\n",
      "        [1.5734e-27, 2.1787e-29, 8.5102e-10],\n",
      "        [4.1072e-40, 6.4579e-36, 1.9873e-11],\n",
      "        [2.5167e-37, 8.2488e-36, 7.1243e-12],\n",
      "        [5.0784e-40, 1.2668e-34, 8.1838e-11],\n",
      "        [3.5174e-25, 1.0928e-29, 2.6070e-10],\n",
      "        [5.9091e-39, 1.1254e-37, 1.2609e-12],\n",
      "        [1.6989e-37, 2.8123e-36, 3.6026e-12],\n",
      "        [4.4961e-37, 4.5044e-34, 6.1464e-11],\n",
      "        [3.3348e-31, 1.9109e-31, 3.1727e-10],\n",
      "        [3.3603e-34, 3.5008e-33, 8.1593e-11],\n",
      "        [1.4308e-30, 1.1741e-32, 2.7338e-11],\n",
      "        [1.8556e-26, 3.6755e-30, 2.2272e-10]], grad_fn=<ExpBackward>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = naive_bayes.guide(None, None)\n",
    "\n",
    "print((model(data_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
